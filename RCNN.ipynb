{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RCNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1FVbZRZa1FdQGh33mAIIq9NDFED0i7YEJ",
      "authorship_tag": "ABX9TyP6J8DinWTaF3IL8wH79Pny",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cwoonb/RCNN/blob/main/RCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDytDLmb8FeY",
        "outputId": "d3360f5c-899f-475c-e05d-95a7bd393a6b"
      },
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Hu1t1l59f87",
        "outputId": "a88bdedf-d502-4355-f62a-a1eada9d9452"
      },
      "source": [
        "!ls ./dataset"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "val2017\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzcSe5B1_gUR"
      },
      "source": [
        "# cho_woonbae 2021.08.09\n",
        "# Do not copy without permission"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gs4DRwmd-f9V"
      },
      "source": [
        "# Data load\n",
        "import zipfile\n",
        "with zipfile.ZipFile('./val2017.zip') as data_zip:\n",
        "    data_zip.extractall('./data')\n",
        "with zipfile.ZipFile('./panoptic_annotations_trainval2017.zip') as data_zip:\n",
        "    data_zip.extractall('./annotation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpaDYhZy-hwS"
      },
      "source": [
        "# Parameters\n",
        "\n",
        "ano_dir = './annotation/annotations/panoptic_val2017.json'\n",
        "root_dir = './data/val2017/'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mj7MSKBI-iJd"
      },
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import numpy as np\n",
        "def get_items(ano_dir):\n",
        "    with open(ano_dir, 'r') as f:\n",
        "        temp = json.loads(''.join(f.readlines()))\n",
        "    image_list = []\n",
        "    ctg_df = pd.DataFrame(temp['categories']).reset_index()\n",
        "    ctg_df['index'] = ctg_df['index'] + np.ones(len(ctg_df), dtype=np.int64)\n",
        "    id2ctg = dict(ctg_df.set_index('index')['id'])\n",
        "    ctg2id = dict(ctg_df.set_index('id')['index'])\n",
        "    for a in temp['annotations']:\n",
        "        image_id = a['file_name'][:-4]\n",
        "        bbox = np.stack(marking['bbox'])\n",
        "        labels = np.asarray([ctg2id[l] for l in marking['category_id']])\n",
        "        image_list.append({'image_id':image_id, 'bbox':bbox, 'labels':labels})\n",
        "    return np.asarray(image_list), id2ctg\n",
        "\n",
        "image_list, id2ctg = get_items(ano_dir)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opNfqQIv-iM3"
      },
      "source": [
        "# train_valid_split\n",
        "from random import sample\n",
        "def get_tv_idx(tl, k = 0.8):\n",
        "    total_idx = range(tl)\n",
        "    train_idx = sample(total_idx, int(tl*0.8))\n",
        "    valid_idx = set(total_idx) - set(train_idx)\n",
        "    return train_idx, list(valid_idx)\n",
        "\n",
        "train_idx, valid_idx = get_tv_idx(len(image_list))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVBP0Prl-iQu"
      },
      "source": [
        "train_list = image_list[train_idx]\n",
        "valid_list = image_list[valid_idx]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kmOnXRl-iT0"
      },
      "source": [
        "def get_iou(bb1, bb2):\n",
        "    assert bb1[0] < bb1[1]\n",
        "    assert bb1[2] < bb1[3]\n",
        "    assert bb2['x1'] < bb2['x2']\n",
        "    assert bb2['y1'] < bb2['y2']\n",
        "    x_left = max(bb1[0], bb2['x1'])\n",
        "    y_top = max(bb1[2], bb2['y1'])\n",
        "    x_right = min(bb1[1], bb2['x2'])\n",
        "    y_bottom = min(bb1[3], bb2['y2'])\n",
        "    if x_right < x_left or y_bottom < y_top:\n",
        "        return 0.0\n",
        "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
        "    bb1_area = (bb1[1] - bb1[0]) * (bb1[3] - bb1[2])\n",
        "    bb2_area = (bb2['x2'] - bb2['x1']) * (bb2['y2'] - bb2['y1'])\n",
        "    iou = intersection_area / float(bb1_area + bb2_area - intersection_area)\n",
        "    assert iou >= 0.0\n",
        "    assert iou <= 1.0\n",
        "    return iou\n",
        "\n",
        "    # Selective Search로 추출한 이미지에 배경인지(0) Object인지 (1~133) 판단하기 위해 IoU를 계산해 겹치는 부분을 확인합니다.\n",
        "    "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSNkRi6j-iWd"
      },
      "source": [
        "import cv2\n",
        "ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
        "\n",
        "def SelectiveSearch(t):\n",
        "    train_images=[]\n",
        "    train_labels=[]\n",
        "\n",
        "    img_id = t['image_id']\n",
        "    img = cv2.imread(f'{root_dir}{img_id}.jpg')\n",
        "\n",
        "    ss.setBaseImage(img)\n",
        "    ss.switchToSelectiveSearchFast()\n",
        "    ssresults = ss.process()\n",
        "    # print(len(ssresults))\n",
        "\n",
        "    imout = img.copy()\n",
        "    counter = 0\n",
        "    falsecounter = 0\n",
        "    flag = 0\n",
        "    fflag = 0\n",
        "    bflag = 0\n",
        "    boxes = t['bbox']\n",
        "    x2 = boxes[:,0] + boxes[:,2]\n",
        "    y2 = boxes[:,1] + boxes[:,3]\n",
        "    boxes = np.c_[boxes, x2, y2][:,[0,4,1,5]]\n",
        "    for _,result in enumerate(ssresults):\n",
        "        if _ < 2000 and flag == 0:\n",
        "            for i, gtval in enumerate(boxes):\n",
        "                x,y,w,h = result\n",
        "                iou = get_iou(gtval, {\"x1\":x,\"x2\":x+w,\"y1\":y,\"y2\":y+h})\n",
        "                if counter < 30:\n",
        "                  # 0.7 보다 클때 이값은 iourㅏ 오브젝트로 판단\n",
        "                    if iou > 0.70:\n",
        "                        timage = imout[y:y+h,x:x+w]\n",
        "                        resized = cv2.resize(timage, (224,224), interpolation = cv2.INTER_AREA)\n",
        "                        train_images.append(resized)\n",
        "                        train_labels.append(t['labels'][i])\n",
        "                        counter += 1\n",
        "                else :\n",
        "                    fflag =1\n",
        "                if falsecounter <30:\n",
        "                                    # 0.3보다 작을때는 배경으로 레이블링 한다. \n",
        "                                    \n",
        "                    if iou < 0.3:\n",
        "                        timage = imout[y:y+h,x:x+w]\n",
        "                        resized = cv2.resize(timage, (224,224), interpolation = cv2.INTER_AREA)\n",
        "                        train_images.append(resized)\n",
        "                        train_labels.append(0)\n",
        "                        falsecounter += 1\n",
        "                else :\n",
        "                    bflag = 1\n",
        "            if fflag == 1 and bflag == 1:\n",
        "                # print(\"inside\")\n",
        "                flag = 1\n",
        "\n",
        "    return np.array(train_images, dtype=np.uint8), np.array(train_labels, dtype=np.int_)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2hriyav-iZG"
      },
      "source": [
        "model = SEMobileNet(num_classes=10) # se net and mobile net을 합친것이다. \n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/Study_AI/semob_10class.pth'))\n",
        "# 프리 트레인 모델을 가져오고 파라미터를 가져온다. \n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "model.classifier = nn.Sequential(nn.Linear(1024, 4096),\n",
        "                    nn.Linear(4096, len(id2ctg)+1)) \n",
        "model.cuda()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ofmc5qPU-ibu"
      },
      "source": [
        "import torch.optim as optim\n",
        "# Linear SVM Loss MSE\n",
        "criterion = nn.CrossEntropyLoss().cuda()\n",
        "optimizer = optim.SGD(model.parameters(),lr=0.01, momentum=0.9, weight_decay=0.0005)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ko9-RDEF-ieq"
      },
      "source": [
        "from torchvision import transforms\n",
        "train_transform = transforms.Compose([\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.RandomVerticalFlip(p=0.5),\n",
        "                                      transforms.RandomHorizontalFlip(p=0.5),\n",
        "])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei0Jw8gc-imN"
      },
      "source": [
        "# torch형태의 모델이다. \n",
        "from tqdm.notebook import tqdm\n",
        "total_loss = 0.0\n",
        "tk0 = tqdm(train_list, total=len(train_list), leave=False)\n",
        "# 4000장 * 60 = 12000\n",
        "for idx, t in enumerate(tk0, 0):\n",
        "    image_data, label_data = SelectiveSearch(t)\n",
        "    inputs = torch.cat(tuple(train_transform(id).cuda().reshape(-1, 3, 224, 224) for id in image_data))\n",
        "    labels = torch.Tensor(label_data).cuda()\n",
        "    labels = labels.type(torch.long)\n",
        "\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss += loss.item()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}